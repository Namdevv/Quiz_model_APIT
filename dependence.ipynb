{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d81c09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
      "Collecting xformers==0.0.32.post2\n",
      "  Using cached xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n",
      "Collecting peft\n",
      "  Using cached peft-0.17.1-py3-none-any.whl (504 kB)\n",
      "Collecting trl\n",
      "  Using cached trl-0.22.2-py3-none-any.whl (544 kB)\n",
      "Requirement already satisfied: triton in ./venv/lib/python3.10/site-packages (3.4.0)\n",
      "Collecting cut_cross_entropy\n",
      "  Using cached cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Collecting unsloth_zoo\n",
      "  Using cached unsloth_zoo-2025.9.2-py3-none-any.whl (197 kB)\n",
      "Installing collected packages: xformers, unsloth_zoo, trl, peft, cut_cross_entropy, bitsandbytes, accelerate\n",
      "Successfully installed accelerate-1.10.1 bitsandbytes-0.47.0 cut_cross_entropy-25.1.1 peft-0.17.1 trl-0.22.2 unsloth_zoo-2025.9.2 xformers-0.0.32.post2\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "Collecting protobuf\n",
      "  Using cached protobuf-6.32.0-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
      "Collecting datasets<4.0.0,>=3.4.1\n",
      "  Using cached datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Collecting huggingface_hub>=0.34.0\n",
      "  Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "Collecting hf_transfer\n",
      "  Using cached hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Collecting pyarrow>=15.0.0\n",
      "  Using cached pyarrow-21.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.7 MB)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./venv/lib/python3.10/site-packages (from datasets<4.0.0,>=3.4.1) (2.32.5)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from datasets<4.0.0,>=3.4.1) (25.0)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in ./venv/lib/python3.10/site-packages (from datasets<4.0.0,>=3.4.1) (2024.6.1)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from datasets<4.0.0,>=3.4.1) (3.13.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from datasets<4.0.0,>=3.4.1) (6.0.2)\n",
      "Collecting multiprocess<0.70.17\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from datasets<4.0.0,>=3.4.1) (2.1.2)\n",
      "Collecting tqdm>=4.66.3\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0\n",
      "  Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3\n",
      "  Using cached hf_xet-1.1.9-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.10/site-packages (from huggingface_hub>=0.34.0) (4.12.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Using cached aiohttp-3.12.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1) (2025.8.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1) (2.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas->datasets<4.0.0,>=3.4.1) (2.9.0.post0)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1) (25.3.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.6.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting propcache>=0.2.0\n",
      "  Using cached propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (198 kB)\n",
      "Collecting aiosignal>=1.4.0\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Collecting async-timeout<6.0,>=4.0\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Using cached yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (222 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0.0,>=3.4.1) (1.17.0)\n",
      "Installing collected packages: pytz, xxhash, tzdata, tqdm, sentencepiece, pyarrow, protobuf, propcache, multidict, hf-xet, hf_transfer, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, pandas, multiprocess, huggingface_hub, aiosignal, aiohttp, datasets\n"
     ]
    }
   ],
   "source": [
    "import torch, re, os\n",
    "\n",
    "# Lấy version Torch đang cài\n",
    "v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
    "xformers = \"xformers==\" + (\"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\")\n",
    "\n",
    "# Cài tất cả thư viện\n",
    "!pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
    "!pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
    "!pip install unsloth\n",
    "!pip install transformers==4.55.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d78196fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 11 files:   0%|                                 | 0/11 [00:00<?, ?it/s]Still waiting to acquire lock on models/Llama-3.2-3B-Instruct/.cache/huggingface/.gitignore.lock (elapsed: 0.1 seconds)\n",
      "Still waiting to acquire lock on models/Llama-3.2-3B-Instruct/.cache/huggingface/.gitignore.lock (elapsed: 0.1 seconds)\n",
      "Downloading 'model.safetensors.index.json' to 'models/Llama-3.2-3B-Instruct/.cache/huggingface/download/yVzAsSxRSINSz-tQbpx-TLpfkLU=.d3a1f0f5f401eeadca0c7a6786bd9e877fd42e58.incomplete'\n",
      "Downloading '.gitattributes' to 'models/Llama-3.2-3B-Instruct/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.52373fe24473b1aa44333d318f578ae6bf04b49b.incomplete'\n",
      "\n",
      "model.safetensors.index.json: 0.00B [00:00, ?B/s]\u001b[A\n",
      "\n",
      ".gitattributes: 1.57kB [00:00, 7.99MB/s]A\n",
      "model.safetensors.index.json: 20.9kB [00:00, 10.5MB/s]\n",
      "Download complete. Moving file to models/Llama-3.2-3B-Instruct/model.safetensors.index.json\n",
      "Download complete. Moving file to models/Llama-3.2-3B-Instruct/.gitattributes\n",
      "Downloading 'README.md' to 'models/Llama-3.2-3B-Instruct/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.faad9b8cd9ff4ff8fd6f5ec0776fe8bff64fc5cf.incomplete'\n",
      "Downloading 'generation_config.json' to 'models/Llama-3.2-3B-Instruct/.cache/huggingface/download/3EVKVggOldJcKSsGjSdoUCN1AyQ=.cabfc63e394c9abfc712a7c6f9a21d4e050fade8.incomplete'\n",
      "Fetching 11 files:   9%|██▎                      | 1/11 [00:00<00:05,  1.76it/s]Downloading 'model-00001-of-00002.safetensors' to 'models/Llama-3.2-3B-Instruct/.cache/huggingface/download/aoe4E07IMh7reFyUkVoVk040mQk=.13cbd6d16e927a0c5bad54102514e6e18b4a47b3a6eb911e39d678d328d19f55.incomplete'\n",
      "\n",
      "README.md: 0.00B [00:00, ?B/s]\u001b[A\n",
      "\n",
      "generation_config.json: 100%|███████████████████| 234/234 [00:00<00:00, 362kB/s]\u001b[A\u001b[A\n",
      "README.md: 5.74kB [00:00, 1.16MB/s]\n",
      "Download complete. Moving file to models/Llama-3.2-3B-Instruct/README.md\n",
      "Download complete. Moving file to models/Llama-3.2-3B-Instruct/generation_config.json\n",
      "Downloading 'model-00002-of-00002.safetensors' to 'models/Llama-3.2-3B-Instruct/.cache/huggingface/download/Dr_lZJDwE1cnGAQMwA77jJEQIk8=.7b770216613ac5c34d7c54bdff1fa616bc4e338a9d0b20af6303e48c295ee23c.incomplete'\n",
      "Downloading 'special_tokens_map.json' to 'models/Llama-3.2-3B-Instruct/.cache/huggingface/download/ahkChHUJFxEmOdq5GDFEmerRzCY=.3c1d04911c269b925af977a3151c9704e990e4d0.incomplete'\n",
      "Downloading 'tokenizer.json' to 'models/Llama-3.2-3B-Instruct/.cache/huggingface/download/HgM_lKo9sdSCfRtVg7MMFS7EKqo=.6b9e4e7fb171f92fd137b777cc2714bf87d11576700a1dcd7a399e7bbe39537b.incomplete'\n",
      "\n",
      "special_tokens_map.json: 100%|█████████████████| 454/454 [00:00<00:00, 4.77MB/s]\u001b[A\n",
      "Download complete. Moving file to models/Llama-3.2-3B-Instruct/special_tokens_map.json\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|             | 0.00/4.97G [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:   0%|             | 0.00/1.46G [00:00<?, ?B/s]\u001b[A\u001b[ADownloading 'tokenizer_config.json' to 'models/Llama-3.2-3B-Instruct/.cache/huggingface/download/vzaExXFZNBay89bvlQv-ZcI6BTg=.3dc1faa6025cdb195c0889dd8d3d13ca26af9225.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "tokenizer_config.json: 54.7kB [00:00, 48.1MB/s]A\u001b[A\n",
      "Download complete. Moving file to models/Llama-3.2-3B-Instruct/tokenizer_config.json\n",
      "Downloading 'chat_template.jinja' to 'models/Llama-3.2-3B-Instruct/.cache/huggingface/download/yIUQ6Jg7XpBWXEkozaEkS2ih05g=.1bad6a0f648dccdbec523ca79ba90fbcfc806af0.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "chat_template.jinja: 3.83kB [00:00, 17.0MB/s]A\u001b[A\n",
      "Download complete. Moving file to models/Llama-3.2-3B-Instruct/chat_template.jinja\n",
      "Fetching 11 files:  27%|██████▊                  | 3/11 [00:01<00:02,  2.67it/s]\n",
      "\n",
      "\n",
      "tokenizer.json:   0%|                               | 0.00/17.2M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "tokenizer.json: 100%|██████████████████████| 17.2M/17.2M [00:01<00:00, 10.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to models/Llama-3.2-3B-Instruct/tokenizer.json\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|  | 6.24M/4.97G [00:06<1:20:07, 1.03MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   0%|    | 15.1M/4.97G [00:06<28:25, 2.90MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   0%|    | 24.5M/4.97G [00:06<16:02, 5.13MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1%|    | 31.5M/4.97G [00:06<11:09, 7.37MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   2%|     | 116M/4.97G [00:07<02:05, 38.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 199M/4.97G [00:07<01:01, 76.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5%|▎    | 266M/4.97G [00:08<01:05, 72.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7%|▎    | 333M/4.97G [00:09<00:53, 86.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8%|▍     | 400M/4.97G [00:09<00:39, 117MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11%|▋     | 534M/4.97G [00:09<00:24, 179MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12%|▋     | 601M/4.97G [00:09<00:19, 218MB/s]\u001b[ADownloading 'config.json' to 'models/Llama-3.2-3B-Instruct/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.c9b6f554d5eda244e63d96d82c41696ee99abcb7.incomplete'\n",
      "\n",
      "model-00001-of-00002.safetensors:  14%|▊     | 687M/4.97G [00:10<00:16, 253MB/s]\u001b[A\n",
      "\n",
      "\n",
      "config.json: 100%|██████████████████████████████| 890/890 [00:00<00:00, 500kB/s]\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to models/Llama-3.2-3B-Instruct/config.json\n",
      "Fetching 11 files:  36%|█████████                | 4/11 [00:11<00:26,  3.83s/it]\n",
      "model-00001-of-00002.safetensors:  16%|▉     | 806M/4.97G [00:10<00:19, 210MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19%|█▏    | 940M/4.97G [00:11<00:13, 304MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20%|█    | 1.01G/4.97G [00:11<00:11, 344MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:   0%|   | 5.82M/1.46G [00:16<1:10:16, 345kB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  22%|▊   | 1.08G/4.97G [00:16<01:25, 45.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  34%|█▋   | 1.66G/4.97G [00:16<00:19, 173MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  17%|▊    | 251M/1.46G [00:17<01:00, 20.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  21%|█    | 311M/1.46G [00:25<01:22, 13.9MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  38%|█▌  | 1.90G/4.97G [00:27<00:53, 57.2MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  26%|█▎   | 378M/1.46G [00:31<01:21, 13.3MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  38%|█▌  | 1.91G/4.97G [00:31<01:12, 42.2MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  31%|█▌   | 446M/1.46G [00:33<01:04, 15.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  35%|█▊   | 513M/1.46G [00:41<01:15, 12.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  36%|█▊   | 519M/1.46G [00:42<01:15, 12.5MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  41%|█▋  | 2.06G/4.97G [00:42<01:50, 26.3MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  38%|█▉   | 548M/1.46G [00:42<01:00, 15.1MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  42%|█▋  | 2.08G/4.97G [00:43<01:49, 26.4MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  38%|█▉   | 554M/1.46G [00:43<01:03, 14.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  43%|██▏  | 621M/1.46G [00:44<00:38, 21.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  43%|██▏  | 634M/1.46G [00:47<00:54, 15.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  48%|██▍  | 701M/1.46G [00:47<00:28, 26.7MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  45%|█▊  | 2.24G/4.97G [00:47<01:33, 29.1MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  50%|██▍  | 730M/1.46G [00:48<00:23, 31.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  55%|██▋  | 797M/1.46G [00:49<00:17, 38.6MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  47%|█▊  | 2.32G/4.97G [00:49<01:22, 32.0MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  56%|██▊  | 813M/1.46G [00:49<00:17, 37.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  58%|██▉  | 842M/1.46G [00:50<00:13, 44.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  61%|███  | 897M/1.46G [00:50<00:08, 66.3MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  48%|█▉  | 2.41G/4.97G [00:51<01:12, 35.1MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  65%|███▎ | 952M/1.46G [00:51<00:07, 66.4MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  54%|██▏ | 2.68G/4.97G [00:54<00:45, 50.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55%|██▏ | 2.72G/4.97G [00:54<00:41, 54.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55%|██▏ | 2.75G/4.97G [00:55<00:47, 46.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  57%|██▎ | 2.81G/4.97G [00:56<00:36, 59.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  58%|██▎ | 2.87G/4.97G [00:56<00:29, 71.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  60%|██▍ | 2.96G/4.97G [00:56<00:23, 84.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  61%|██▍ | 3.02G/4.97G [00:57<00:22, 86.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  62%|██▍ | 3.09G/4.97G [00:58<00:19, 97.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  64%|███▏ | 3.17G/4.97G [00:58<00:16, 111MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  65%|██▌ | 3.21G/4.97G [00:59<00:22, 79.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  66%|███▎ | 3.28G/4.97G [00:59<00:15, 112MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  74%|██▉ | 1.08G/1.46G [00:59<00:16, 22.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  92%|███▋| 1.34G/1.46G [01:00<00:02, 56.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  95%|███▊| 1.39G/1.46G [01:02<00:01, 47.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors: 100%|████| 1.46G/1.46G [01:05<00:00, 22.5MB/s]\u001b[A\u001b[A\n",
      "Download complete. Moving file to models/Llama-3.2-3B-Instruct/model-00002-of-00002.safetensors\n",
      "\n",
      "model-00001-of-00002.safetensors:  75%|███ | 3.74G/4.97G [01:06<00:16, 72.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  83%|███▎| 4.10G/4.97G [01:16<00:17, 50.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  91%|███▋| 4.51G/4.97G [01:16<00:05, 84.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  92%|███▋| 4.57G/4.97G [01:19<00:05, 73.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  94%|███▋| 4.65G/4.97G [01:19<00:03, 82.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  95%|███▊| 4.72G/4.97G [01:20<00:02, 83.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  96%|███▊| 4.79G/4.97G [01:20<00:01, 91.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  98%|███▉| 4.86G/4.97G [01:21<00:01, 79.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  99%|███▉| 4.92G/4.97G [01:23<00:00, 69.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors: 100%|████| 4.97G/4.97G [01:25<00:00, 58.1MB/s]\u001b[A\n",
      "Download complete. Moving file to models/Llama-3.2-3B-Instruct/model-00001-of-00002.safetensors\n",
      "Fetching 11 files: 100%|████████████████████████| 11/11 [01:27<00:00,  7.99s/it]\n",
      "/mnt/d/Nam_Workspace/Quiz_model_llm/models/Llama-3.2-3B-Instruct\n"
     ]
    }
   ],
   "source": [
    "!hf download unsloth/Llama-3.2-3B-Instruct --local-dir ./models/Llama-3.2-3B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbce10a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hf download Namtran0912/Llama-3.2-3B-Instruct-lora-adapter-10ep --local-dir ./models/Llama-3.2-3B-Instruct-lora-adapter-10ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c8662e-0e9d-4791-aca5-838f638c7e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
